{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, RationalQuadratic, ExpSineSquared, ConstantKernel\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement (component 1)(kg in a m^3 mixture)</th>\n",
       "      <th>Blast Furnace Slag (component 2)(kg in a m^3 mixture)</th>\n",
       "      <th>Fly Ash (component 3)(kg in a m^3 mixture)</th>\n",
       "      <th>Water  (component 4)(kg in a m^3 mixture)</th>\n",
       "      <th>Superplasticizer (component 5)(kg in a m^3 mixture)</th>\n",
       "      <th>Coarse Aggregate  (component 6)(kg in a m^3 mixture)</th>\n",
       "      <th>Fine Aggregate (component 7)(kg in a m^3 mixture)</th>\n",
       "      <th>Age (day)</th>\n",
       "      <th>Concrete compressive strength(MPa, megapascals)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.986111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.887366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.269535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.052780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.296075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement (component 1)(kg in a m^3 mixture)  \\\n",
       "0                                      540.0   \n",
       "1                                      540.0   \n",
       "2                                      332.5   \n",
       "3                                      332.5   \n",
       "4                                      198.6   \n",
       "\n",
       "   Blast Furnace Slag (component 2)(kg in a m^3 mixture)  \\\n",
       "0                                                0.0       \n",
       "1                                                0.0       \n",
       "2                                              142.5       \n",
       "3                                              142.5       \n",
       "4                                              132.4       \n",
       "\n",
       "   Fly Ash (component 3)(kg in a m^3 mixture)  \\\n",
       "0                                         0.0   \n",
       "1                                         0.0   \n",
       "2                                         0.0   \n",
       "3                                         0.0   \n",
       "4                                         0.0   \n",
       "\n",
       "   Water  (component 4)(kg in a m^3 mixture)  \\\n",
       "0                                      162.0   \n",
       "1                                      162.0   \n",
       "2                                      228.0   \n",
       "3                                      228.0   \n",
       "4                                      192.0   \n",
       "\n",
       "   Superplasticizer (component 5)(kg in a m^3 mixture)  \\\n",
       "0                                                2.5     \n",
       "1                                                2.5     \n",
       "2                                                0.0     \n",
       "3                                                0.0     \n",
       "4                                                0.0     \n",
       "\n",
       "   Coarse Aggregate  (component 6)(kg in a m^3 mixture)  \\\n",
       "0                                             1040.0      \n",
       "1                                             1055.0      \n",
       "2                                              932.0      \n",
       "3                                              932.0      \n",
       "4                                              978.4      \n",
       "\n",
       "   Fine Aggregate (component 7)(kg in a m^3 mixture)  Age (day)  \\\n",
       "0                                              676.0         28   \n",
       "1                                              676.0         28   \n",
       "2                                              594.0        270   \n",
       "3                                              594.0        365   \n",
       "4                                              825.5        360   \n",
       "\n",
       "   Concrete compressive strength(MPa, megapascals)   \n",
       "0                                         79.986111  \n",
       "1                                         61.887366  \n",
       "2                                         40.269535  \n",
       "3                                         41.052780  \n",
       "4                                         44.296075  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset for Concrete strength\n",
    "df_concrete = pd.read_excel('Concrete_Data.xls')\n",
    "df_concrete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(\n",
    "    df_concrete[df_concrete.columns[:-1]],\n",
    "    df_concrete[df_concrete.columns[-1]],\n",
    "    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbeepi/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/kbeepi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/kbeepi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#Standardizing the prepared training and test data\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svr_param_selection(X, y, nfolds):\n",
    "    Kernels = ['linear', 'poly', 'rbf']\n",
    "    Cs = [0.001, 0.01, 0.1, 1]\n",
    "    Gammas = [0.001, 0.01, 0.1]\n",
    "    param_grid = {'kernel':Kernels, 'C': Cs, 'gamma' : Gammas}\n",
    "    grid_search = GridSearchCV(SVR(), param_grid, cv=nfolds, n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    print('SVR Lowest MSE Score: '+str(grid_search.best_score_))\n",
    "    print('SVR With Parameters: '+str(grid_search.best_params_))    \n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_regressor_param_selection(X, y, nfolds):\n",
    "    Estimators = np.arange(1,100,15)\n",
    "    Max_features = ['auto', 'sqrt']\n",
    "    Min_samples_leafs = np.linspace(0.01, 0.05, 5, endpoint=True)\n",
    "    param_grid = {'n_estimators': Estimators, 'max_features': Max_features, 'min_samples_leaf': Min_samples_leafs}\n",
    "    grid_search = GridSearchCV(RandomForestRegressor(random_state=0), param_grid, cv=nfolds, n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    print('RandomForestRegressor Lowest MSE Score: '+str(grid_search.best_score_))\n",
    "    print('RandomForestRegressor With Parameters: '+str(grid_search.best_params_))    \n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_regressor_param_selection(X, y, nfolds):\n",
    "    Max_features = ['auto', 'sqrt']\n",
    "    Min_samples_leafs = np.linspace(0.01, 0.05, 5, endpoint=True)\n",
    "    param_grid = {'max_features': Max_features, 'min_samples_leaf': Min_samples_leafs}\n",
    "    grid_search = GridSearchCV(DecisionTreeRegressor(random_state=0), param_grid, cv=nfolds, n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    print('DecisionTreeRegressor Lowest MSE Score: '+str(grid_search.best_score_))\n",
    "    print('DecisionTreeRegressor With Parameters: '+str(grid_search.best_params_))    \n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ada_boost_regressor_param_selection(X, y, nfolds):\n",
    "    Estimators = np.arange(1,100,15)\n",
    "    Learning_rates = [0.01,0.05,0.1,0.3]\n",
    "    Losses = ['linear', 'square', 'exponential']\n",
    "    param_grid = {'n_estimators': Estimators, 'learning_rate': Learning_rates, 'loss': Losses}\n",
    "    grid_search = GridSearchCV(AdaBoostRegressor(base_estimator=DecisionTreeRegressor(random_state=0),random_state=0), param_grid, cv=nfolds, n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    print('AdaBoostRegressor Lowest MSE Score:'+str(grid_search.best_score_))\n",
    "    print('AdaBoostRegressor With Parameters:'+str(grid_search.best_params_))    \n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_regressor_param_selection(X, y, nfolds):\n",
    "    kernel_rbf = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")\n",
    "    kernel_rq = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * RationalQuadratic(alpha=0.1, length_scale=1)\n",
    "    kernel_expsine = ConstantKernel(1.0, constant_value_bounds=\"fixed\") * ExpSineSquared(1.0, 5.0, periodicity_bounds=(1e-2, 1e1))\n",
    "    Kernels = [kernel_rbf, kernel_rq, kernel_expsine]\n",
    "    param_grid = {'kernel': Kernels}\n",
    "    grid_search = GridSearchCV(GaussianProcessRegressor(random_state=0), param_grid, cv=nfolds, n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    print('GaussianRegressor Lowest MSE Score:'+str(grid_search.best_score_))\n",
    "    print('GaussianRegressor With Parameters:'+str(grid_search.best_params_))    \n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regressor_param_selection(X, y, nfolds):\n",
    "    param_grid = {'fit_intercept':[True,False], 'normalize':[True,False], 'copy_X':[True, False]}\n",
    "    grid_search = GridSearchCV(LinearRegression(), param_grid, cv=nfolds, n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    print('LinearRegressor Lowest MSE Score:'+str(grid_search.best_score_))\n",
    "    print('LinearRegressor With Parameters:'+str(grid_search.best_params_))    \n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network_regressor_param_selection(X, y, nfolds):\n",
    "    Learning_rates = ['constant','adaptive']\n",
    "    Learning_rates_init = [0.001, 0.01, 0.1, 0.3]\n",
    "    Hidden_Layer_Sizes = [1, 5, 10, (5,5), (10,5)]\n",
    "    Activations = ['logistic', 'tanh', 'relu']\n",
    "    Alphas = [0.0001,0.002]\n",
    "    param_grid = {'learning_rate': Learning_rates, 'learning_rate_init': Learning_rates_init, 'hidden_layer_sizes': Hidden_Layer_Sizes, 'activation': Activations, 'alpha': Alphas}\n",
    "    grid_search = GridSearchCV(MLPRegressor(max_iter=900), param_grid, cv=nfolds, n_jobs=-1)\n",
    "    grid_search.fit(X, y)\n",
    "    print('NeuralNetworkRegressor Lowest MSE Score:'+str(grid_search.best_score_))\n",
    "    print('NeuralNetworkRegressor With Parameters:'+str(grid_search.best_params_))    \n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now =2019-11-30 15:56:09.097298\n",
      "SVR Lowest MSE Score: 0.5789762542375352\n",
      "SVR With Parameters: {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "now =2019-11-30 15:56:12.259973\n",
      "RandomForestRegressor Lowest MSE Score: 0.8508792501196476\n",
      "RandomForestRegressor With Parameters: {'max_features': 'auto', 'min_samples_leaf': 0.01, 'n_estimators': 76}\n",
      "now =2019-11-30 15:56:17.943343\n",
      "DecisionTreeRegressor Lowest MSE Score: 0.7727221652459776\n",
      "DecisionTreeRegressor With Parameters: {'max_features': 'auto', 'min_samples_leaf': 0.01}\n",
      "now =2019-11-30 15:56:18.024184\n",
      "AdaBoostRegressor Lowest MSE Score:0.8850710284639528\n",
      "AdaBoostRegressor With Parameters:{'learning_rate': 0.1, 'loss': 'linear', 'n_estimators': 91}\n",
      "now =2019-11-30 15:56:37.961864\n",
      "LinearRegressor Lowest MSE Score:0.5975838735846647\n",
      "LinearRegressor With Parameters:{'copy_X': True, 'fit_intercept': True, 'normalize': True}\n",
      "now =2019-11-30 15:56:38.540474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbeepi/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetworkRegressor Lowest MSE Score:0.8648833544664216\n",
      "NeuralNetworkRegressor With Parameters:{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': 10, 'learning_rate': 'adaptive', 'learning_rate_init': 0.01}\n",
      "now =2019-11-30 16:00:45.012777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbeepi/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (900) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#Using the 3-Fold HyperParam Search to evaluate the best hyperparams for each model\n",
    "print(\"now =\"+str(datetime.now()))\n",
    "svr_best_param           = svr_param_selection(x_train_scaled, y_train, 3)\n",
    "print(\"now =\"+str(datetime.now()))\n",
    "random_forest_best_param = random_forest_regressor_param_selection(x_train_scaled, y_train, 3)\n",
    "print(\"now =\"+str(datetime.now()))\n",
    "decision_tree_best_param = decision_tree_regressor_param_selection(x_train_scaled, y_train, 3)\n",
    "print(\"now =\"+str(datetime.now()))\n",
    "ada_boost_best_param     = ada_boost_regressor_param_selection(x_train_scaled, y_train, 3)\n",
    "print(\"now =\"+str(datetime.now()))\n",
    "linear_best_param         = linear_regressor_param_selection(x_train_scaled, y_train, 3)\n",
    "print(\"now =\"+str(datetime.now()))\n",
    "neural_network_best_param = neural_network_regressor_param_selection(x_train_scaled, y_train, 3)\n",
    "print(\"now =\"+str(datetime.now()))\n",
    "#gaussian_best_param       = gaussian_regressor_param_selection(x_train_scaled, y_train, 3)\n",
    "#print(\"now =\"+str(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking MSE of each of the best regressors on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now =2019-11-30 16:00:45.168509\n",
      "SVR Lowest MSE Score: 0.5789762542375352\n",
      "SVR With Parameters: {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "now =2019-11-30 16:00:46.506435\n"
     ]
    }
   ],
   "source": [
    "print(\"now =\"+str(datetime.now()))\n",
    "svr_best_param           = svr_param_selection(x_train_scaled, y_train, 3)\n",
    "print(\"now =\"+str(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for SVR: 88.90869983425155\n"
     ]
    }
   ],
   "source": [
    "best_svr = SVR(C=1, gamma=0.1, kernel='rbf')\n",
    "best_svr.fit(x_train_scaled, y_train)\n",
    "y_pred = best_svr.predict(x_test_scaled)\n",
    "print('MSE for SVR: '+str(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Decision Tree Regressor: 90.66119976316396\n"
     ]
    }
   ],
   "source": [
    "best_decision_tree_regressor = DecisionTreeRegressor(max_features='auto', min_samples_leaf=0.05, random_state=0)\n",
    "best_decision_tree_regressor.fit(x_train_scaled, y_train)\n",
    "y_pred = best_decision_tree_regressor.predict(x_test_scaled)\n",
    "print('MSE for Decision Tree Regressor: '+str(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Random Forest Regressor: 35.03771745627268\n"
     ]
    }
   ],
   "source": [
    "best_random_forest_regressor = RandomForestRegressor(max_features='auto', min_samples_leaf=0.01, n_estimators=91, random_state=0)\n",
    "best_random_forest_regressor.fit(x_train_scaled, y_train)\n",
    "y_pred = best_random_forest_regressor.predict(x_test_scaled)\n",
    "print('MSE for Random Forest Regressor: '+str(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for AdaBoost Regressor: 74.09779355022897\n"
     ]
    }
   ],
   "source": [
    "best_ada_boost_regressor = AdaBoostRegressor(learning_rate=0.01, loss='linear', n_estimators=91, random_state=0)\n",
    "best_ada_boost_regressor.fit(x_train_scaled, y_train)\n",
    "y_pred = best_ada_boost_regressor.predict(x_test_scaled)\n",
    "print('MSE for AdaBoost Regressor: '+str(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Linear Regressor: 95.90413603681108\n"
     ]
    }
   ],
   "source": [
    "best_linear_regressor = LinearRegression(copy_X=True, fit_intercept=True, normalize=True)\n",
    "best_linear_regressor.fit(x_train_scaled, y_train)\n",
    "y_pred = best_linear_regressor.predict(x_test_scaled)\n",
    "print('MSE for Linear Regressor: '+str(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Neural Network Regressor: 146.85836251586838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbeepi/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "best_neural_network_regressor = MLPRegressor(activation='logistic', alpha=0.002, hidden_layer_sizes=(10, 5), learning_rate='constant', learning_rate_init=0.01, random_state=0)\n",
    "best_neural_network_regressor.fit(x_train_scaled, y_train)\n",
    "y_pred = best_neural_network_regressor.predict(x_test_scaled)\n",
    "print('MSE for Neural Network Regressor: '+str(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
